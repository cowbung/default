{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "specialized-implementation",
   "metadata": {},
   "source": [
    "# 미니 프로젝트: 가위바위보 분류기를 만들자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-upgrade",
   "metadata": {},
   "source": [
    "### PIL 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "frank-paintball",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-folks",
   "metadata": {},
   "source": [
    "### 이미지 사이즈 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "requested-washer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861  images to be resized.\n",
      "861  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "parental-replica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969  images to be resized.\n",
      "969  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "posted-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832  images to be resized.\n",
      "832  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "import os\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-horse",
   "metadata": {},
   "source": [
    "### load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extensive-difference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 2662 입니다.\n",
      "x_train shape: (2662, 28, 28, 3)\n",
      "y_train shape: (2662,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=2662):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "conditional-american",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[2661])\n",
    "print('라벨: ', y_train[2661])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-conditioning",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "realistic-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              820224    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 828,387\n",
      "Trainable params: 828,387\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-bankruptcy",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "charged-suggestion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84/84 [==============================] - 6s 29ms/step - loss: 13.7164 - accuracy: 0.4928\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.2923 - accuracy: 0.9015\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1614 - accuracy: 0.9503\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9787\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9655\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9945\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9947\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff889c178d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-wholesale",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "valued-halifax",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path, 300)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_test_norm.shape))\n",
    "print(\"y_train shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "limited-apparel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - loss: 1.0796 - accuracy: 0.6533\n",
      "test_loss: 1.0796098709106445 \n",
      "test_accuracy: 0.6533333325386047\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-horizon",
   "metadata": {},
   "source": [
    "### 후기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-happening",
   "metadata": {},
   "source": [
    "훈련 용 데이터는 아지트에서 공유된 것을 사용하였고, 테스트 용 데이터는 기본 제공되는 것을 사용하였다.\n",
    "초기 결과는 30퍼센트 대의 정확도로 매우 좋지 않았고 다음과 같이 해당 요인들을 개선하여 정확도를 높일 수 있었다.\n",
    "\n",
    "1. 공유된 학습 용 데이터의 품질이 매우 좋지 않았다. 같은 레이블 안에서 일관성이 부족하였고 이미지의 난잡한 백그라운드는 데이터를 무가치하게 만들었다. 수작업으로 데이터를 정제하여 품질을 높였으며 그러면서도 데이터의 충분한 분량과 다양성을 유지하려고 노력하였다.\n",
    "\n",
    "2. 하이퍼파라미터 설정에서 Conv2D 레이어의 이미지 특징의 수는 너무 많지 않게, Dense 레이어의 뉴런 수는 충분한 값으로 늘려나가면서 테스트를 반복하였다.\n",
    "\n",
    "3. 학습과 테스트를 반복하면 동일한 데이터와 동일한 설정에서도 매번 정확도 결과의 편차가 큰데, 이것은 학습 용 데이터의 품질이 여전히 좋지 않기 때문인 것으로 생각된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
